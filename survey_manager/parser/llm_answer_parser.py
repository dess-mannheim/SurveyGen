
from typing import List

from utilities.survey_classes.survey_objects import SurveyQuestion, SurveyOptions

from inference.survey_inference import batch_generation

from vllm import LLM

class LLMAnswerParser:

    DEFAULT_SYSTEM_PROMPT: str = "You are a helpful assistant."
    DEFAULT_PROMPT: str = "Your task is to parse the correct answer option from an open text answer a LLM has given to survey questions. You will be provided with the possible answer options and the full text answer. Answer ONLY and EXACTLY with one of the possible answer options or 'INVALID', if the provided answer does give on of the options."

    @staticmethod
    def llm_parser_single(model:LLM, answers:List[str], survey_questions: List[SurveyQuestion], system_prompt:str = DEFAULT_SYSTEM_PROMPT, prompt:str = DEFAULT_PROMPT, use_structured_ouput:bool = False, batch_size:int = 2) -> str:
        assert len(answers) == len(survey_questions), "Answers need to be same length as survey questions!"
        
        results = []
        for i in range(0, len(survey_questions), batch_size):

            batch:List[SurveyQuestion] = survey_questions[i:i + batch_size]
            
            survey_prompts = []
            structured_output_options: List[List[str]] = []
            j = 0
            for survey_question in batch:
                options_string = survey_question.options.create_options_str()

                survey_prompt = f"""{prompt}
{options_string}
Answer of the LLM: '{answers[i + j]}'"""
                survey_prompts.append(survey_prompt)
                structured_output_options.append(survey_question.options.option_descriptions + ["INVALID"])
                j += 1
            #print(structured_output_options)
            if use_structured_ouput:
                output = batch_generation(system_messages=[system_prompt]*len(survey_prompts), prompts=survey_prompts, structured_ouput_options=structured_output_options, temperature=0)
            else:
                print("No structured Output!")
                print(survey_prompts)
                output = batch_generation(system_messages=[system_prompt]*len(survey_prompts), prompts=survey_prompts, temperature=0)
            #print(output)
            results.extend(output)
        model.shutdown()
        return results

    @staticmethod
    def llm_parser_whole_survey(model_id:str, answer:str, survey_questions: List[SurveyQuestion], fallback_text:bool = True, fallback_number:bool = False, system_prompt:str = DEFAULT_SYSTEM_PROMPT, prompt:str = DEFAULT_PROMPT) -> str:
        pass

    @staticmethod
    def single_regex_parser(answer:str, survey_question:SurveyQuestion, fallback_text:bool = True, fallback_number:bool = False, separate_char:str = ":") -> str:
        """
        Finds last occurence of a survey answer option.
        :param answer: The answer generated by the LLM
        :param survey_question: The survey question object. Has to contain option values
        """
        assert survey_question.options, "Options have to exist to be able to parse them."

        candidates = []
        for option in survey_question.options.option_descriptions:
            idx = answer.rfind(option)
            if idx != -1:
                candidates.append((option, idx))
                continue
            
            for line in option.strip().splitlines():
                if separate_char in line:
                    number, text = line.split(separate_char, 1)
                    if fallback_text:
                        idx = answer.rfind(" " + text.strip())
                        if idx != -1:
                            candidates.append((option, idx))
                            continue
                    if fallback_number:
                        idx = answer.rfind(number.strip())
                        if idx != -1:
                            candidates.append((option, idx))
                            continue
        if len(candidates) == 0:
            print(answer)
            return "INVALID"
        else:
            #print(candidates)
            return max(candidates, key=lambda x: x[1])[0]
    
    @staticmethod
    def survey_regex_parser(answer:str, survey_questions:List[SurveyQuestion], fallback_text:bool = True, fallback_number:bool = False, separate_char:str = ":") -> List[str]:
        """
        Finds last occurence of a survey answer option.
        :param answer: The answer generated by the LLM
        :param survey_question: The survey question object. Has to contain option values
        """
        for survey_question in survey_questions:
            assert survey_question.options.option_descriptions, "Options have to exist to be able to parse them."

        num_questions = len(survey_questions)

        survey_answers = []

        current_survey_question_idx = 0

        for answer_line in answer.strip().splitlines():
            for option in survey_questions[current_survey_question_idx].options.option_descriptions:
                idx = answer_line.rfind(option)
                if idx != -1:
                    survey_answers.append(option)
                    current_survey_question_idx += 1
                    if current_survey_question_idx >= num_questions:
                        return survey_answers
                    break
                for line in option.strip().splitlines():
                    if separate_char in line:
                        number, text = line.split(separate_char, 1)
                        if fallback_text:
                            idx = answer_line.rfind(text.strip())
                            if idx != -1:
                                survey_answers.append(option)
                                current_survey_question_idx += 1
                                if current_survey_question_idx >= num_questions:
                                    return survey_answers
                                break
                        if fallback_number:
                            idx = answer_line.rfind(number.strip())
                            if idx != -1:
                                survey_answers.append(option)
                                current_survey_question_idx += 1
                                if current_survey_question_idx >= num_questions:
                                    return survey_answers
                                break

        return survey_answers
